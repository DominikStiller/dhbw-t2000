# Load-aware scheduler for large-scale neural network autotuning
This repository contains the thesis detailing a novel method to decompose autotuning with [TVM](https://tvm.apache.org/) into individual stages and schedule them such that hardware resources are utilized efficiently. The project was conducted at [Hewlett Packard Labs](https://www.hpe.com/us/en/hewlett-packard-labs.html) under the supervision of Dr. Junguk Cho and Dr. Puneet Sharma.

Links:
* See the [thesis](T2000.pdf) for methods and results
* See the [pending patent](https://patents.google.com/patent/US20220129315A1) for the patent application
