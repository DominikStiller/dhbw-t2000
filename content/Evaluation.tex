evaluation environment:
125 GB RAM
Intel Xeon E5-2650 v3, 2.30 GhZ with avx2 instructions
4x Tesla K80 GPU

Python 3.5
on Ubuntu 16.04

\section{Results}
Comparison of interleaved design vs synchronous and sequential in terms of autotuning time and inference time
hardware and network specifications

Evaluation only with limited set of hardware and models, general statement requires more experiments

compare with thesis from introduction

overhead of scheduling

\section{Limitations}
Very rudimentary scheduler
Predictive scheduler using times for task to make scheduling more intelligent
Requires more control in scheduler, not only simplified interface
Add Knows which job is in which stage and how long is each stage estimated to take to load-awareness
running update model and build of one job directly after another will probably decrease waiting time, since that job can then already use the target device, so there is less target device idle time
Believe that more and heterogenous jobs that vary significantly in complexity will enable better resource utilization and less wait time, given a more intelligent scheduler
The scheduler can be enhanced with more granularity for production-grade implementations.